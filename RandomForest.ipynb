{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPZ+6esg6tCtbghCh1Sso+t",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/mlacasa/EstadisticaQ2/blob/main/RandomForest.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#🚀 Ejercicio: Evaluación de un Modelo Random Forest\n",
        "¡Bienvenido/a a este ejercicio práctico! El objetivo es construir y evaluar un modelo de clasificación utilizando el algoritmo Random Forest. Para ello, trabajaremos con el conocido dataset \"Pima Indians Diabetes\", que contiene información diagnóstica de pacientes para predecir la aparición de diabetes.\n",
        "\n",
        "A lo largo de este cuaderno, seguiremos los pasos clave para entrenar y validar un modelo de machine learning de forma rigurosa.\n",
        "\n",
        "##Paso 1: Carga y Preparación de los Datos\n",
        "Toda gran aventura en machine learning comienza con los datos. En esta primera celda, realizaremos las tareas fundamentales de preparación para dejar nuestro dataset listo para el entrenamiento.\n",
        "\n",
        "Los pasos que ejecutará el siguiente código son:\n",
        "\n",
        "Importar Librerías: Cargaremos las herramientas que necesitaremos, como pandas para manejar los datos y scikit-learn para el preprocesamiento y el modelo.\n",
        "\n",
        "Cargar el Dataset: Accederemos a los datos desde una URL pública y los cargaremos en un DataFrame de pandas, asignando nombres descriptivos a cada columna.\n",
        "\n",
        "Separar Características y Objetivo: Dividiremos el dataset en dos partes:\n",
        "\n",
        "X: Las variables predictoras (ej. 'Glucosa', 'IMC', 'Edad').\n",
        "\n",
        "y: La variable objetivo que queremos predecir ('Outcome', si la paciente tiene o no diabetes).\n",
        "\n",
        "Dividir en Entrenamiento y Prueba: Separaremos nuestros datos en un conjunto de entrenamiento (80%) y uno de prueba (20%). Esto es crucial para evaluar de forma honesta el rendimiento del modelo en datos que no ha visto previamente.\n",
        "\n",
        "Escalar las Características: Aunque Random Forest no es tan sensible a la escala de las variables como los modelos lineales, es una buena práctica estandarizar los datos. Usaremos StandardScaler para asegurar que todas las características tengan una media de 0 y una desviación estándar de 1.\n",
        "\n",
        "¡Empecemos!"
      ],
      "metadata": {
        "id": "eIni8TtlhZy5"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tLatMXutjEGJ"
      },
      "outputs": [],
      "source": [
        "# --- 1. IMPORTACIÓN DE LIBRERÍAS ---\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "\n",
        "# --- 2. CARGA DEL DATASET ---\n",
        "# Se accede al dataset desde una URL pública del repositorio de UCI\n",
        "url = \"https://raw.githubusercontent.com/jbrownlee/Datasets/master/pima-indians-diabetes.data.csv\"\n",
        "column_names = ['Embarazos', 'Glucosa', 'Presion', 'Piel', 'Insulina', 'IMC', 'Pedigri', 'Edad', 'Outcome']\n",
        "data = pd.read_csv(url, names=column_names)\n",
        "\n",
        "print(\"--- Primeras 5 filas del dataset ---\")\n",
        "print(data.head())\n",
        "\n",
        "# --- 3. SEPARACIÓN DE CARACTERÍSTICAS (X) Y OBJETIVO (y) ---\n",
        "X = data.drop('Outcome', axis=1)\n",
        "y = data['Outcome']\n",
        "\n",
        "# --- 4. DIVISIÓN EN CONJUNTOS DE ENTRENAMIENTO Y PRUEBA ---\n",
        "# Se utiliza stratify=y para mantener la proporción de 0s y 1s en ambos conjuntos\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42, stratify=y)\n",
        "\n",
        "print(f\"\\nNúmero de muestras de entrenamiento: {X_train.shape[0]}\")\n",
        "print(f\"Número de muestras de prueba: {X_test.shape[0]}\")\n",
        "\n",
        "# --- 5. ESCALADO DE CARACTERÍSTICAS ---\n",
        "# Se crea el objeto escalador\n",
        "scaler = StandardScaler()\n",
        "\n",
        "# Se ajusta el escalador SÓLO con los datos de entrenamiento para evitar fuga de información\n",
        "X_train_scaled = scaler.fit_transform(X_train)\n",
        "\n",
        "# Se aplica la misma transformación a los datos de prueba\n",
        "X_test_scaled = scaler.transform(X_test)\n",
        "\n",
        "print(\"\\n¡Datos listos para el entrenamiento del modelo!\")"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Paso 2: Entrenamiento y Evaluación del Modelo Random Forest\n",
        "Ahora que nuestros datos están listos, vamos a entrenar nuestro modelo Random Forest. Este algoritmo es un \"ensamblaje\", lo que significa que construye múltiples árboles de decisión y combina sus predicciones para obtener un resultado más preciso y robusto.\n",
        "\n",
        "En esta celda, realizaremos tres análisis clave para entender nuestro modelo:\n",
        "\n",
        "Evaluación de Rendimiento: Crearemos una matriz de confusión detallada y un reporte de clasificación para medir qué tan bien funciona nuestro \"bosque\" en la tarea de predicción.\n",
        "\n",
        "Análisis de Importancia de Variables: Una de las grandes ventajas de Random Forest es que puede decirnos qué variables fueron más importantes para tomar sus decisiones. Lo visualizaremos con un gráfico de barras.\n",
        "\n",
        "Visualización de un Árbol Individual: Para entender qué hay dentro del \"bosque\", aislaremos y dibujaremos uno de los árboles de decisión que lo componen. Esto nos dará una idea de las reglas que el modelo aprende."
      ],
      "metadata": {
        "id": "HiOZCYVAh6v8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Se asume que las variables X_train_scaled, X_test_scaled, y_train, y_test están disponibles.\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.tree import DecisionTreeClassifier, plot_tree\n",
        "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "# --- 1. ENTRENAMIENTO DEL MODELO RANDOM FOREST ---\n",
        "# Instanciamos el modelo con random_state para que los resultados sean reproducibles\n",
        "rf_model = RandomForestClassifier(n_estimators=100, random_state=42, n_jobs=-1)\n",
        "\n",
        "print(\"--- Entrenando el modelo Random Forest ---\")\n",
        "rf_model.fit(X_train_scaled, y_train)\n",
        "\n",
        "# Realizar predicciones en el conjunto de prueba\n",
        "y_pred_rf = rf_model.predict(X_test_scaled)\n",
        "\n",
        "\n",
        "# --- 2. EVALUACIÓN DE RENDIMIENTO ---\n",
        "print(\"\\n--- Matriz de Confusión del Modelo Random Forest ---\")\n",
        "cm = confusion_matrix(y_test, y_pred_rf)\n",
        "tn, fp, fn, tp = cm.ravel()\n",
        "accuracy = accuracy_score(y_test, y_pred_rf)\n",
        "\n",
        "# Crear etiquetas detalladas para la matriz de confusión\n",
        "labels = np.array([\n",
        "    f\"Verdadero Negativo\\n\\n{tn}\", f\"Falso Positivo\\n\\n{fp}\",\n",
        "    f\"Falso Negativo\\n\\n{fn}\", f\"Verdadero Positivo\\n\\n{tp}\"\n",
        "]).reshape(2, 2)\n",
        "\n",
        "# Visualizar la matriz\n",
        "plt.figure(figsize=(8, 6))\n",
        "sns.heatmap(cm, annot=labels, fmt='', cmap='Blues', cbar=False, annot_kws={\"size\": 14})\n",
        "plt.title(f'Matriz de Confusión (Exactitud Global: {accuracy:.2%})', fontsize=16)\n",
        "plt.ylabel('Etiqueta Real', fontsize=12)\n",
        "plt.xlabel('Etiqueta Predicha', fontsize=12)\n",
        "plt.show()\n",
        "\n",
        "print(\"\\n--- Reporte de Clasificación ---\")\n",
        "print(classification_report(y_test, y_pred_rf))\n",
        "\n",
        "\n",
        "# --- 3. ANÁLISIS DE IMPORTANCIA DE VARIABLES ---\n",
        "# Extraer la importancia de cada característica\n",
        "importances = rf_model.feature_importances_\n",
        "feature_names = X.columns\n",
        "\n",
        "# Crear un DataFrame para la visualización\n",
        "importance_df = pd.DataFrame({'Variable': feature_names, 'Importancia': importances})\n",
        "importance_df = importance_df.sort_values(by='Importancia', ascending=False)\n",
        "\n",
        "# Graficar la importancia de las variables\n",
        "plt.figure(figsize=(12, 8))\n",
        "sns.barplot(x='Importancia', y='Variable', data=importance_df, palette='viridis')\n",
        "plt.title('Importancia de las Variables según Random Forest', fontsize=16)\n",
        "plt.xlabel('Importancia Relativa', fontsize=12)\n",
        "plt.ylabel('Variable', fontsize=12)\n",
        "plt.show()\n",
        "\n",
        "\n",
        "# --- 4. VISUALIZACIÓN DE UN ÁRBOL INDIVIDUAL DEL BOSQUE ---\n",
        "# Vamos a visualizar el primer árbol del bosque (índice 0)\n",
        "single_tree = rf_model.estimators_[0]\n",
        "\n",
        "plt.figure(figsize=(20, 10))\n",
        "# Dibujar el árbol con una profundidad máxima de 3 para que sea legible\n",
        "plot_tree(single_tree,\n",
        "          feature_names=X.columns,\n",
        "          class_names=['Sano', 'Diabético'],\n",
        "          filled=True,\n",
        "          rounded=True,\n",
        "          max_depth=3,\n",
        "          fontsize=10)\n",
        "plt.title('Visualización de un Árbol de Decisión Individual del Bosque', fontsize=18)\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "90ibrJJhk3qP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "## Paso 3: Optimización con GridSearchCV y Comparación de Resultados\n",
        "Aunque nuestro modelo Random Forest inicial tuvo un buen rendimiento, casi siempre es posible mejorarlo mediante la optimización de hiperparámetros. En lugar de usar los valores por defecto del modelo, vamos a buscar la combinación de parámetros que ofrezca el mejor resultado para nuestro dataset específico.\n",
        "\n",
        "¿Cómo lo haremos?\n",
        "\n",
        "Definir una \"Parrilla\" de Búsqueda: Crearemos un diccionario (param_grid) con los hiperparámetros clave de Random Forest que queremos probar (como el número de árboles, la profundidad máxima, etc.) y una lista de posibles valores para cada uno.\n",
        "\n",
        "Usar GridSearchCV: Esta potente herramienta de scikit-learn probará sistemáticamente todas las combinaciones posibles de la parrilla utilizando validación cruzada. Esto asegura que encontremos la mejor combinación de forma robusta.\n",
        "\n",
        "Comparar Antes y Después: Una vez que GridSearchCV encuentre el mejor modelo, generaremos un gráfico comparativo para ver si hemos logrado una mejora en 5 métricas clave (Accuracy, Precision, Recall,"
      ],
      "metadata": {
        "id": "S7G5td4piZtc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Se asume que las variables X_train_scaled, X_test_scaled, y_train, y_test\n",
        "# y el modelo 'rf_model' por defecto están disponibles.\n",
        "\n",
        "# --- 0. LIBRERÍAS Y FUNCIONES DE AYUDA ---\n",
        "from sklearn.model_selection import GridSearchCV, RandomizedSearchCV\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, roc_auc_score\n",
        "import pandas as pd\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "from scipy.stats import randint, uniform\n",
        "\n",
        "# Librerías para la barra de progreso\n",
        "from tqdm.notebook import tqdm\n",
        "import joblib\n",
        "import contextlib\n",
        "\n",
        "# --- PASO PREVIO: EVALUACIÓN DEL MODELO BASE ---\n",
        "print(\"--- Evaluación del Modelo Base ---\")\n",
        "y_pred_base = rf_model.predict(X_test_scaled)\n",
        "y_prob_base = rf_model.predict_proba(X_test_scaled)[:, 1]\n",
        "\n",
        "base_metrics = {\n",
        "    'Accuracy': accuracy_score(y_test, y_pred_base),\n",
        "    'Precision': precision_score(y_test, y_pred_base),\n",
        "    'Recall': recall_score(y_test, y_pred_base),\n",
        "    'F1 Score': f1_score(y_test, y_pred_base),\n",
        "    'AUC': roc_auc_score(y_test, y_prob_base)\n",
        "}\n",
        "\n",
        "print(\"Métricas del modelo base:\")\n",
        "for metric, value in base_metrics.items():\n",
        "    print(f\"{metric}: {value:.4f}\")\n",
        "\n",
        "target_auc = base_metrics['AUC']\n",
        "print(f\"\\nObjetivo: Superar AUC de {target_auc:.4f}\")\n",
        "\n",
        "# --- 1. DEFINICIÓN DE MÚLTIPLES ESTRATEGIAS DE BÚSQUEDA ---\n",
        "print(\"\\n--- Paso 1: Definiendo Estrategias de Búsqueda ---\")\n",
        "\n",
        "# Estrategia 1: Grid básico (más conservador)\n",
        "param_grid_basic = {\n",
        "    'n_estimators': [100, 200, 300],\n",
        "    'max_depth': [10, 15, 20, None],\n",
        "    'min_samples_split': [2, 5],\n",
        "    'min_samples_leaf': [1, 2],\n",
        "    'max_features': ['sqrt', 'log2']\n",
        "}\n",
        "\n",
        "# Estrategia 2: Grid amplio (más exploración)\n",
        "param_grid_extended = {\n",
        "    'n_estimators': [50, 100, 200, 300, 500],\n",
        "    'max_depth': [5, 10, 15, 20, 25, None],\n",
        "    'min_samples_split': [2, 5, 10, 20],\n",
        "    'min_samples_leaf': [1, 2, 4, 8],\n",
        "    'max_features': ['sqrt', 'log2', 0.3, 0.5, 0.7],\n",
        "    'bootstrap': [True, False],\n",
        "    'criterion': ['gini', 'entropy']\n",
        "}\n",
        "\n",
        "# Estrategia 3: Randomized Search (para espacios muy grandes)\n",
        "param_dist_random = {\n",
        "    'n_estimators': randint(50, 500),\n",
        "    'max_depth': [5, 10, 15, 20, 25, 30, None],\n",
        "    'min_samples_split': randint(2, 25),\n",
        "    'min_samples_leaf': randint(1, 10),\n",
        "    'max_features': uniform(0.1, 0.9),\n",
        "    'bootstrap': [True, False],\n",
        "    'criterion': ['gini', 'entropy']\n",
        "}\n",
        "\n",
        "# --- 2. FUNCIÓN PARA EJECUTAR BÚSQUEDA CON BARRA DE PROGRESO ---\n",
        "@contextlib.contextmanager\n",
        "def tqdm_joblib(tqdm_object):\n",
        "    \"\"\"Context manager para que joblib (motor de GridSearchCV) informe a tqdm.\"\"\"\n",
        "    class TqdmBatchCompletionCallback(joblib.parallel.BatchCompletionCallBack):\n",
        "        def __call__(self, *args, **kwargs):\n",
        "            tqdm_object.update(n=self.batch_size)\n",
        "            return super().__call__(*args, **kwargs)\n",
        "\n",
        "    old_batch_callback = joblib.parallel.BatchCompletionCallBack\n",
        "    joblib.parallel.BatchCompletionCallBack = TqdmBatchCompletionCallback\n",
        "    try:\n",
        "        yield\n",
        "    finally:\n",
        "        joblib.parallel.BatchCompletionCallBack = old_batch_callback\n",
        "        tqdm_object.close()\n",
        "\n",
        "def execute_search(search_object, description, total_fits):\n",
        "    \"\"\"Ejecuta la búsqueda con barra de progreso\"\"\"\n",
        "    print(f\"\\n{description}\")\n",
        "    print(f\"Se realizarán {total_fits} ajustes del modelo.\")\n",
        "\n",
        "    with tqdm_joblib(tqdm(desc=description, total=total_fits)):\n",
        "        search_object.fit(X_train_scaled, y_train)\n",
        "\n",
        "    return search_object\n",
        "\n",
        "# --- 3. ESTRATEGIA ADAPTATIVA DE BÚSQUEDA ---\n",
        "print(\"\\n--- Paso 2: Ejecutando Búsqueda Adaptativa ---\")\n",
        "\n",
        "best_search = None\n",
        "best_auc = 0\n",
        "strategies_tried = []\n",
        "\n",
        "# Estrategia 1: Grid básico\n",
        "try:\n",
        "    print(\"\\n=== ESTRATEGIA 1: Grid Básico ===\")\n",
        "    n_candidates_basic = np.prod([len(v) for v in param_grid_basic.values()])\n",
        "    total_fits_basic = n_candidates_basic * 3  # cv=3\n",
        "\n",
        "    grid_search_basic = GridSearchCV(\n",
        "        estimator=RandomForestClassifier(random_state=42, n_jobs=-1),\n",
        "        param_grid=param_grid_basic,\n",
        "        scoring='roc_auc',\n",
        "        cv=3,\n",
        "        verbose=0\n",
        "    )\n",
        "\n",
        "    grid_search_basic = execute_search(grid_search_basic, \"Grid Básico\", total_fits_basic)\n",
        "    basic_auc = grid_search_basic.best_score_\n",
        "\n",
        "    strategies_tried.append({\n",
        "        'strategy': 'Grid Básico',\n",
        "        'best_auc': basic_auc,\n",
        "        'best_params': grid_search_basic.best_params_,\n",
        "        'search_object': grid_search_basic\n",
        "    })\n",
        "\n",
        "    print(f\"Mejor AUC con Grid Básico: {basic_auc:.4f}\")\n",
        "\n",
        "    if basic_auc > best_auc:\n",
        "        best_auc = basic_auc\n",
        "        best_search = grid_search_basic\n",
        "\n",
        "except Exception as e:\n",
        "    print(f\"Error en Grid Básico: {e}\")\n",
        "\n",
        "# Si el grid básico no mejora suficiente, probar estrategia extendida\n",
        "if best_auc < target_auc + 0.01:  # Margen de mejora mínimo\n",
        "    try:\n",
        "        print(\"\\n=== ESTRATEGIA 2: Grid Extendido ===\")\n",
        "        print(\"El grid básico no proporcionó mejora suficiente. Probando grid extendido...\")\n",
        "\n",
        "        n_candidates_ext = min(np.prod([len(v) for v in param_grid_extended.values()]), 500)  # Limitar a 500 combinaciones\n",
        "        total_fits_ext = n_candidates_ext * 3\n",
        "\n",
        "        # Si hay demasiadas combinaciones, usar RandomizedSearchCV\n",
        "        if n_candidates_ext > 200:\n",
        "            print(\"Demasiadas combinaciones. Usando RandomizedSearchCV...\")\n",
        "            grid_search_extended = RandomizedSearchCV(\n",
        "                estimator=RandomForestClassifier(random_state=42, n_jobs=-1),\n",
        "                param_distributions=param_dist_random,\n",
        "                n_iter=150,  # Número de iteraciones\n",
        "                scoring='roc_auc',\n",
        "                cv=3,\n",
        "                verbose=0,\n",
        "                random_state=42\n",
        "            )\n",
        "            total_fits_ext = 150 * 3\n",
        "        else:\n",
        "            grid_search_extended = GridSearchCV(\n",
        "                estimator=RandomForestClassifier(random_state=42, n_jobs=-1),\n",
        "                param_grid=param_grid_extended,\n",
        "                scoring='roc_auc',\n",
        "                cv=3,\n",
        "                verbose=0\n",
        "            )\n",
        "\n",
        "        grid_search_extended = execute_search(grid_search_extended, \"Grid Extendido/Randomized\", total_fits_ext)\n",
        "        extended_auc = grid_search_extended.best_score_\n",
        "\n",
        "        strategies_tried.append({\n",
        "            'strategy': 'Grid Extendido/Randomized',\n",
        "            'best_auc': extended_auc,\n",
        "            'best_params': grid_search_extended.best_params_,\n",
        "            'search_object': grid_search_extended\n",
        "        })\n",
        "\n",
        "        print(f\"Mejor AUC con Grid Extendido: {extended_auc:.4f}\")\n",
        "\n",
        "        if extended_auc > best_auc:\n",
        "            best_auc = extended_auc\n",
        "            best_search = grid_search_extended\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"Error en Grid Extendido: {e}\")\n",
        "\n",
        "# --- 4. VALIDACIÓN DE MEJORA ---\n",
        "print(f\"\\n--- Validación de Resultados ---\")\n",
        "print(f\"AUC modelo base: {target_auc:.4f}\")\n",
        "print(f\"Mejor AUC encontrado: {best_auc:.4f}\")\n",
        "\n",
        "if best_search is None:\n",
        "    print(\"❌ ERROR: No se pudo ejecutar ninguna estrategia de búsqueda.\")\n",
        "    best_search = GridSearchCV(\n",
        "        estimator=RandomForestClassifier(random_state=42, n_jobs=-1),\n",
        "        param_grid={'n_estimators': [200], 'max_depth': [15]},\n",
        "        scoring='roc_auc',\n",
        "        cv=3\n",
        "    )\n",
        "    best_search.fit(X_train_scaled, y_train)\n",
        "\n",
        "elif best_auc <= target_auc:\n",
        "    print(\"⚠️  ADVERTENCIA: No se logró mejorar significativamente el modelo base.\")\n",
        "    print(\"Recomendaciones:\")\n",
        "    print(\"1. Revisar la calidad y preprocesamiento de los datos\")\n",
        "    print(\"2. Considerar feature engineering adicional\")\n",
        "    print(\"3. Probar otros algoritmos (XGBoost, LightGBM)\")\n",
        "    print(\"4. Ajustar la métrica de evaluación si es necesario\")\n",
        "else:\n",
        "    improvement = ((best_auc - target_auc) / target_auc) * 100\n",
        "    print(f\"✅ ÉXITO: Mejora del {improvement:.2f}% en AUC\")\n",
        "\n",
        "# --- 5. RESUMEN DE ESTRATEGIAS PROBADAS ---\n",
        "print(f\"\\n--- Resumen de Estrategias ---\")\n",
        "strategies_df = pd.DataFrame(strategies_tried)\n",
        "if not strategies_df.empty:\n",
        "    strategies_df = strategies_df.sort_values('best_auc', ascending=False)\n",
        "    print(strategies_df[['strategy', 'best_auc']].to_string(index=False))\n",
        "\n",
        "# --- 6. ANÁLISIS DE LA EVOLUCIÓN DE LA BÚSQUEDA ---\n",
        "print(\"\\n--- Análisis de la Evolución de Resultados ---\")\n",
        "cv_results_df = pd.DataFrame(best_search.cv_results_)\n",
        "\n",
        "# Seleccionar columnas relevantes dinámicamente\n",
        "param_cols = [col for col in cv_results_df.columns if col.startswith('param_')]\n",
        "relevant_cols = param_cols + ['mean_test_score', 'mean_fit_time']\n",
        "available_cols = [col for col in relevant_cols if col in cv_results_df.columns]\n",
        "\n",
        "cv_summary_df = cv_results_df[available_cols].copy()\n",
        "cv_summary_df = cv_summary_df.rename(columns={'mean_test_score': 'AUC_Medio', 'mean_fit_time': 'Tiempo_Ajuste_s'})\n",
        "cv_summary_df = cv_summary_df.fillna('None')\n",
        "\n",
        "print(\"Mejores 10 combinaciones de hiperparámetros encontradas:\")\n",
        "print(cv_summary_df.sort_values(by='AUC_Medio', ascending=False).head(10))\n",
        "\n",
        "# Gráfico de evolución (adaptativo según parámetros disponibles)\n",
        "if 'param_n_estimators' in cv_summary_df.columns:\n",
        "    plt.figure(figsize=(12, 7))\n",
        "\n",
        "    # Usar max_depth si está disponible, sino usar otro parámetro\n",
        "    size_param = None\n",
        "    hue_param = None\n",
        "\n",
        "    if 'param_max_depth' in cv_summary_df.columns:\n",
        "        size_param = 'param_max_depth'\n",
        "        hue_param = 'param_max_depth'\n",
        "    elif 'param_min_samples_split' in cv_summary_df.columns:\n",
        "        size_param = 'param_min_samples_split'\n",
        "        hue_param = 'param_min_samples_split'\n",
        "\n",
        "    if size_param and hue_param:\n",
        "        sns.scatterplot(data=cv_summary_df, x='param_n_estimators', y='AUC_Medio',\n",
        "                       size=size_param, hue=hue_param, palette='viridis',\n",
        "                       sizes=(50, 250), alpha=0.7)\n",
        "        plt.legend(title=size_param.replace('param_', ''))\n",
        "    else:\n",
        "        sns.scatterplot(data=cv_summary_df, x='param_n_estimators', y='AUC_Medio', alpha=0.7)\n",
        "\n",
        "    plt.title('Evolución del Rendimiento (AUC) vs. Hiperparámetros', fontsize=16)\n",
        "    plt.xlabel('Número de Árboles (n_estimators)', fontsize=12)\n",
        "    plt.ylabel('AUC Medio en Validación Cruzada', fontsize=12)\n",
        "    plt.grid(True, alpha=0.5)\n",
        "    plt.show()\n",
        "\n",
        "# --- 7. COMPARACIÓN GRÁFICA FINAL ---\n",
        "print(\"\\n--- Comparación Final: Modelo Default vs. Modelo Optimizado ---\")\n",
        "optimized_rf_model = best_search.best_estimator_\n",
        "\n",
        "# Evaluación en conjunto de prueba\n",
        "comparison_results = []\n",
        "\n",
        "# Modelo base\n",
        "comparison_results.append({\n",
        "    'Modelo': 'Base',\n",
        "    'Accuracy': base_metrics['Accuracy'],\n",
        "    'Precision': base_metrics['Precision'],\n",
        "    'Recall': base_metrics['Recall'],\n",
        "    'F1 Score': base_metrics['F1 Score'],\n",
        "    'AUC': base_metrics['AUC']\n",
        "})\n",
        "\n",
        "# Modelo optimizado\n",
        "y_pred_optimized = optimized_rf_model.predict(X_test_scaled)\n",
        "y_prob_optimized = optimized_rf_model.predict_proba(X_test_scaled)[:, 1]\n",
        "\n",
        "comparison_results.append({\n",
        "    'Modelo': 'Optimizado',\n",
        "    'Accuracy': accuracy_score(y_test, y_pred_optimized),\n",
        "    'Precision': precision_score(y_test, y_pred_optimized),\n",
        "    'Recall': recall_score(y_test, y_pred_optimized),\n",
        "    'F1 Score': f1_score(y_test, y_pred_optimized),\n",
        "    'AUC': roc_auc_score(y_test, y_prob_optimized)\n",
        "})\n",
        "\n",
        "df_comparison = pd.DataFrame(comparison_results)\n",
        "print(\"\\nComparación detallada:\")\n",
        "print(df_comparison.round(4))\n",
        "\n",
        "# Gráfico de comparación\n",
        "df_comparison_long = df_comparison.melt(id_vars='Modelo', var_name='Métrica', value_name='Puntuación')\n",
        "\n",
        "plt.figure(figsize=(14, 8))\n",
        "ax = sns.barplot(data=df_comparison_long, x='Métrica', y='Puntuación', hue='Modelo', palette='cividis')\n",
        "\n",
        "for container in ax.containers:\n",
        "    ax.bar_label(container, fmt='%.3f', fontsize=11, padding=3)\n",
        "\n",
        "plt.title('Comparación de Rendimiento: Modelo Base vs. Modelo Optimizado', fontsize=18)\n",
        "plt.xlabel('Métrica de Evaluación', fontsize=14)\n",
        "plt.ylabel('Puntuación', fontsize=14)\n",
        "plt.ylim(0, 1.0)\n",
        "plt.grid(axis='y', linestyle='--', alpha=0.6)\n",
        "plt.legend(title='Versión del Modelo')\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "# --- 8. RECOMENDACIONES FINALES ---\n",
        "print(f\"\\n--- Recomendaciones y Mejores Parámetros ---\")\n",
        "print(f\"Mejores hiperparámetros encontrados:\")\n",
        "for param, value in best_search.best_params_.items():\n",
        "    print(f\"  {param}: {value}\")\n",
        "\n",
        "if best_auc > target_auc:\n",
        "    print(f\"\\n✅ El modelo optimizado muestra mejora significativa.\")\n",
        "    print(f\"   Guardando modelo optimizado...\")\n",
        "    # joblib.dump(optimized_rf_model, 'modelo_optimizado.pkl')\n",
        "else:\n",
        "    print(f\"\\n❌ Considera las siguientes acciones:\")\n",
        "    print(\"   - Revisar ingeniería de características\")\n",
        "    print(\"   - Aumentar el conjunto de datos\")\n",
        "    print(\"   - Probar algoritmos diferentes\")\n",
        "    print(\"   - Ajustar la estrategia de validación cruzada\")"
      ],
      "metadata": {
        "id": "0oEszEVsiUsp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "1s_y9qyYiex2"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}